# Linear Algebra for Machine Learning Series

[![Watch on YouTube](https://img.shields.io/badge/Watch%20on%20YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtube.com/your-channel)
[![GitHub stars](https://img.shields.io/github/stars/w2sg-arnav/Linear-Algebra-for-ML-Series?style=social)](https://github.com/w2sg-arnav/Linear-Algebra-for-ML-Series)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive, from-the-ground-up series on Linear Algebra specifically designed for Machine Learning practitioners. This series combines theoretical foundations with practical implementations and real-world ML applications, incorporating insights from leading courses and resources worldwide.

## üéØ Course Objectives

By the end of this series, you will:
- Master the fundamentals of Linear Algebra from vectors to matrix decompositions
- Understand how Linear Algebra concepts are used in ML algorithms
- Implement key algorithms from scratch using NumPy
- Apply concepts to real ML problems like PCA, SVD, and Neural Networks
- Build intuition through interactive visualizations and examples

Inspired by resources from:
- Gilbert Strang's MIT Linear Algebra
- 3Blue1Brown's Essence of Linear Algebra
- Imperial College London's Mathematics for ML
- DeepLearning.AI's Linear Algebra course
- fast.ai's Computational Linear Algebra

## üìö Series Structure (40 Lectures)

### Module 1: Foundations of Vectors & Spaces (8 Lectures)
- Vectors as the Language of Data
- Dot Products & Similarity Measures
- Vector Spaces & Subspaces
- Linear Independence & Basis
- Orthogonality & Orthonormal Bases
- Norms & Distances
- Advanced Vector Operations
- Vector Calculus Prelude

### Module 2: Matrices as Transformations (10 Lectures)
- Matrices as Linear Transformations
- Matrix Operations & Properties
- Matrix Multiplication Deep Dive
- Special Matrices & Their Properties
- Matrix Inverse & Applications
- Determinants & Volumes
- Solving Linear Systems
- Matrix Factorizations Introduction
- Orthogonal Matrices & Rotations
- Matrix Representations of Data

### Module 3: Dimensionality Reduction & Matrix Decompositions (8 Lectures)
- Eigenvalues & Eigenvectors Fundamentals
- Diagonalization & Matrix Powers
- Positive Definite Matrices
- SVD Foundation
- SVD Applications & Implementation
- PCA Deep Dive
- Non-Negative Matrix Factorization
- Advanced Matrix Factorizations

### Module 4: Advanced Topics & ML Applications (14 Lectures)
- Vector Calculus & Multivariate Differentiation
- Optimization with Linear Algebra
- Numerical Linear Algebra for ML
- Tensors & Multilinear Algebra
- Graph Algorithms & Linear Algebra
- Fourier Analysis & Signal Processing
- Numerical Methods for Linear Systems
- Randomized Linear Algebra
- Positive Matrices & Perron-Frobenius Theory
- Matrix Calculus & Backpropagation
- Reproducing Kernel Hilbert Spaces
- Manifold Learning
- Linear Algebra in Deep Learning
- Future Frontiers in ML Linear Algebra

## üéØ What Makes This Series Unique

- **Visual-First Learning**: Every concept is introduced through intuitive visualizations inspired by 3Blue1Brown
- **Code-Driven Understanding**: Implementations in Python from scratch, then using optimized libraries
- **ML-Focused Examples**: Real applications in neural networks, computer vision, NLP, and more
- **Comprehensive Coverage**: From basic vectors to advanced topics like manifold learning
- **Interactive Learning**: Hands-on exercises, coding challenges, and real-world projects

---

## üìö Series Syllabus & Content

This series is structured into four core modules. Each lecture folder contains a Jupyter notebook with all the code, detailed explanations, and exercises.

### Module 1: The Building Blocks - Vectors, Spaces, and Data Representation
* **[Lecture 01: What is Linear Algebra & Why it Matters for ML?](./lectures/01-Intro-and-Setup)**
* **[Lecture 02: Vectors as Data: A Geometric Intuition](./lectures/02-Vectors-and-Data)**
* **[Lecture 03: The Dot Product: Measuring Similarity and Projection](./lectures/03-Dot-Product-and-Similarity)**

### Module 2: Matrices and Linear Transformations
* **[Lecture 04: Introduction to Matrices and Matrix Operations](./lectures/04-Matrices-Intro)**
* **[Lecture 05: Linear Transformations: A Visual Journey](./lectures/05-Linear-Transformations)**
* **[Lecture 06: Matrix Multiplication as Composition](./lectures/06-Matrix-Multiplication)**

### Module 3: Advanced Concepts and Decompositions
* **[Lecture 07: Eigenvalues and Eigenvectors](./lectures/07-Eigenvalues-Eigenvectors)**
* **[Lecture 08: Principal Component Analysis (PCA)](./lectures/08-PCA)**
* **[Lecture 09: Singular Value Decomposition (SVD)](./lectures/09-SVD)**

### Module 4: Applications in Machine Learning
* **[Lecture 10: Linear Regression and Linear Systems](./lectures/10-Linear-Regression)**
* **[Lecture 11: Neural Networks and Linear Algebra](./lectures/11-Neural-Networks)**
* **[Lecture 12: Dimensionality Reduction in Practice](./lectures/12-Dimensionality-Reduction)**

---

## üöÄ Getting Started

To use this repository and run the code on your own machine, please follow these steps:

1. **Clone the repository:**
   ```bash
   git clone https://github.com/w2sg-arnav/Linear-Algebra-for-ML-Series.git
   cd Linear-Algebra-for-ML-Series
   ```

2. **Set up a virtual environment (recommended):**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. **Install the required libraries:**
   ```bash
   pip install -r requirements.txt
   ```

Now you can open any of the lecture notebooks using Jupyter Lab or VS Code.

## üé• Using This Repository with the Video Series

1. Each lecture folder corresponds to a specific video in the series
2. The notebooks contain:
   - All code shown in the videos
   - Additional explanations and mathematical details
   - Interactive exercises and solutions
   - Extra examples and visualizations

## ü§ù Contributing

Contributions, issues, and feature requests are welcome! If you find an error in the code or a typo in the notes, please don't hesitate to [open an issue](https://github.com/w2sg-arnav/Linear-Algebra-for-ML-Series/issues) or create a pull request.

### How to Contribute:
1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üìß Contact

Have questions? Feel free to reach out:
- YouTube: [Your Channel Name](https://youtube.com/your-channel)
- Twitter: [@YourHandle](https://twitter.com/your-handle)
- LinkedIn: [Your Name](https://linkedin.com/in/your-profile)
