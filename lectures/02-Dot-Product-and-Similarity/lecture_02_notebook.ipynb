{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5289dc41",
   "metadata": {},
   "source": [
    "# Linear Algebra for ML - Lecture 2: The Dot Product - The Heart of Machine Learning\n",
    "\n",
    "Welcome to the second lecture in our comprehensive series on Linear Algebra for Machine Learning. This lecture focuses on the dot product, arguably the most fundamental operation in machine learning.\n",
    "\n",
    "## Learning Objectives\n",
    "- Master both algebraic and geometric interpretations of the dot product\n",
    "- Understand vector projections and their applications\n",
    "- Learn to use cosine similarity in ML applications\n",
    "- Build a single neuron from scratch\n",
    "- Understand how matrix multiplication relates to dot products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520a80a",
   "metadata": {},
   "source": [
    "# Section 1: The Dual Nature of the Dot Product\n",
    "\n",
    "The dot product is unique in having two equivalent interpretations:\n",
    "\n",
    "1. **Algebraically**: Sum of element-wise products\n",
    "   - For vectors a = [a₁, a₂, ..., aₙ] and b = [b₁, b₂, ..., bₙ]\n",
    "   - a · b = a₁b₁ + a₂b₂ + ... + aₙbₙ\n",
    "\n",
    "2. **Geometrically**: Product of lengths and cosine of angle\n",
    "   - a · b = ||a|| ||b|| cos(θ)\n",
    "   - Where ||a|| is the length of vector a and θ is the angle between vectors\n",
    "\n",
    "Let's explore both interpretations using a practical example from movie recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create movie rating vectors (ratings for 4 movies by different users)\n",
    "user_A = np.array([5, 4, 1, 1])  # Likes first two movies\n",
    "user_B = np.array([4, 5, 2, 1])  # Similar taste to A\n",
    "user_C = np.array([1, 2, 5, 4])  # Different taste\n",
    "\n",
    "# Calculate dot products\n",
    "dot_AB = np.dot(user_A, user_B)\n",
    "dot_AC = np.dot(user_A, user_C)\n",
    "\n",
    "print(\"Movie Ratings:\")\n",
    "print(f\"User A: {user_A}\")\n",
    "print(f\"User B: {user_B}\")\n",
    "print(f\"User C: {user_C}\\n\")\n",
    "\n",
    "# Show step-by-step dot product calculation\n",
    "print(\"Dot Product A·B calculation:\")\n",
    "for i, (a, b) in enumerate(zip(user_A, user_B)):\n",
    "    print(f\"Movie {i+1}: {a} * {b} = {a*b}\")\n",
    "print(f\"Sum (A·B) = {dot_AB}\\n\")\n",
    "\n",
    "print(\"Dot Product A·C calculation:\")\n",
    "for i, (a, c) in enumerate(zip(user_A, user_C)):\n",
    "    print(f\"Movie {i+1}: {a} * {c} = {a*c}\")\n",
    "print(f\"Sum (A·C) = {dot_AC}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Higher dot product (A·B) indicates more similar taste\")\n",
    "print(\"- Lower dot product (A·C) indicates different taste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1d849",
   "metadata": {},
   "source": [
    "# Section 2: Geometric Interpretation and Vector Projection\n",
    "\n",
    "The geometric formula for the dot product:\n",
    "\n",
    "$\\mathbf{a} \\cdot \\mathbf{b} = \\|\\mathbf{a}\\| \\|\\mathbf{b}\\| \\cos(\\theta)$\n",
    "\n",
    "This interpretation leads to several important insights:\n",
    "1. When vectors point in the same direction (θ = 0°), cos(θ) = 1, dot product is maximum\n",
    "2. When vectors are perpendicular (θ = 90°), cos(θ) = 0, dot product is zero\n",
    "3. When vectors point in opposite directions (θ = 180°), cos(θ) = -1, dot product is minimum\n",
    "\n",
    "Let's implement functions to explore these geometric properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_length(v):\n",
    "    \"\"\"Calculate the length (magnitude) of a vector\"\"\"\n",
    "    return np.sqrt(np.sum(v**2))\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Calculate the angle between two vectors in degrees\"\"\"\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    lengths_product = vector_length(v1) * vector_length(v2)\n",
    "    cos_theta = dot_product / lengths_product\n",
    "    # Ensure numerical stability\n",
    "    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "    return np.degrees(np.arccos(cos_theta))\n",
    "\n",
    "def project_vector(v, u):\n",
    "    \"\"\"Project vector v onto vector u\"\"\"\n",
    "    # Formula: proj_u(v) = (v·u / ||u||²) * u\n",
    "    u_norm_squared = np.dot(u, u)\n",
    "    scaling = np.dot(v, u) / u_norm_squared\n",
    "    return scaling * u\n",
    "\n",
    "# Example vectors\n",
    "v1 = np.array([1, 0])  # Vector along x-axis\n",
    "v2 = np.array([1, 1])  # Vector at 45 degrees\n",
    "v3 = np.array([0, 1])  # Vector along y-axis\n",
    "v4 = np.array([-1, 0])  # Vector in opposite direction to v1\n",
    "\n",
    "# Calculate angles\n",
    "angles = {\n",
    "    \"v1 and v2\": angle_between(v1, v2),\n",
    "    \"v1 and v3\": angle_between(v1, v3),\n",
    "    \"v1 and v4\": angle_between(v1, v4)\n",
    "}\n",
    "\n",
    "print(\"Angles between vectors:\")\n",
    "for pair, angle in angles.items():\n",
    "    print(f\"{pair}: {angle:.1f} degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize vectors and angles\n",
    "def plot_vectors_and_angles():\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot vectors\n",
    "    vectors = {\n",
    "        'v1': v1,\n",
    "        'v2': v2,\n",
    "        'v3': v3,\n",
    "        'v4': v4\n",
    "    }\n",
    "    \n",
    "    colors = ['blue', 'red', 'green', 'purple']\n",
    "    \n",
    "    # Plot unit circle for reference\n",
    "    circle = plt.Circle((0, 0), 1, fill=False, color='gray', linestyle='--')\n",
    "    plt.gca().add_artist(circle)\n",
    "    \n",
    "    # Plot vectors\n",
    "    for (name, v), color in zip(vectors.items(), colors):\n",
    "        plt.quiver(0, 0, v[0], v[1], angles='xy', scale_units='xy', scale=1,\n",
    "                  color=color, label=name)\n",
    "    \n",
    "    # Add grid and labels\n",
    "    plt.grid(True)\n",
    "    plt.axhline(y=0, color='k', linestyle=':')\n",
    "    plt.axvline(x=0, color='k', linestyle=':')\n",
    "    plt.xlim(-1.5, 1.5)\n",
    "    plt.ylim(-1.5, 1.5)\n",
    "    plt.aspect('equal')\n",
    "    plt.legend()\n",
    "    plt.title('Vector Relationships')\n",
    "    plt.show()\n",
    "\n",
    "plot_vectors_and_angles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d75b9",
   "metadata": {},
   "source": [
    "# Section 3: Cosine Similarity in Machine Learning\n",
    "\n",
    "One of the most common applications of the dot product in ML is cosine similarity:\n",
    "\n",
    "$\\cos(\\theta) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\| \\|\\mathbf{b}\\|}$\n",
    "\n",
    "This measure is useful because:\n",
    "1. It's independent of vector magnitudes (normalized)\n",
    "2. Range is [-1, 1], making it easy to interpret\n",
    "3. Perfect similarity = 1, perfect dissimilarity = -1\n",
    "\n",
    "Let's implement a document similarity system using this concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeff0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, vocab=None):\n",
    "    \"\"\"Convert text to bag-of-words vector\"\"\"\n",
    "    words = text.lower().split()\n",
    "    if vocab is None:\n",
    "        vocab = sorted(set(words))\n",
    "    vector = np.zeros(len(vocab))\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            vector[vocab.index(word)] += 1\n",
    "    return vector, vocab\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm1 = np.linalg.norm(v1)\n",
    "    norm2 = np.linalg.norm(v2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Example documents\n",
    "documents = [\n",
    "    \"I love deep learning\",\n",
    "    \"I love linear algebra\",\n",
    "    \"I love machine learning\"\n",
    "]\n",
    "\n",
    "query = \"I love learning\"\n",
    "\n",
    "# Create vocabulary from all documents and query\n",
    "all_texts = documents + [query]\n",
    "_, vocab = vectorize_text(\" \".join(all_texts))\n",
    "\n",
    "# Vectorize documents and query\n",
    "doc_vectors = [vectorize_text(doc, vocab)[0] for doc in documents]\n",
    "query_vector, _ = vectorize_text(query, vocab)\n",
    "\n",
    "# Calculate similarities\n",
    "similarities = [cosine_similarity(query_vector, doc_vector) \n",
    "               for doc_vector in doc_vectors]\n",
    "\n",
    "# Print results\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nDocument Similarities:\")\n",
    "for doc, sim in zip(documents, similarities):\n",
    "    print(f\"Document: '{doc}'\")\n",
    "    print(f\"Similarity: {sim:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d570e",
   "metadata": {},
   "source": [
    "# Section 4: The Dot Product in Neural Networks\n",
    "\n",
    "At its core, every artificial neuron performs a dot product between its input vector and weight vector, followed by adding a bias term and applying an activation function:\n",
    "\n",
    "$output = activation(\\mathbf{w} \\cdot \\mathbf{x} + b)$\n",
    "\n",
    "Let's implement a simple neuron from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad65e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, num_inputs):\n",
    "        \"\"\"Initialize weights and bias using He initialization\"\"\"\n",
    "        self.weights = np.random.randn(num_inputs) * np.sqrt(2.0/num_inputs)\n",
    "        self.bias = 0\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Compute dot product and add bias\"\"\"\n",
    "        return np.dot(self.weights, inputs) + self.bias\n",
    "    \n",
    "    def activate(self, inputs):\n",
    "        \"\"\"Apply ReLU activation function\"\"\"\n",
    "        return max(0, self.forward(inputs))\n",
    "\n",
    "# Create a neuron with 3 inputs\n",
    "neuron = Neuron(3)\n",
    "\n",
    "# Test with some example inputs\n",
    "example_inputs = [\n",
    "    np.array([0.5, -0.2, 0.1]),\n",
    "    np.array([1.0, 1.0, 1.0]),\n",
    "    np.array([-1.0, -1.0, -1.0])\n",
    "]\n",
    "\n",
    "print(\"Neuron weights:\", neuron.weights)\n",
    "print(\"Neuron bias:\", neuron.bias)\n",
    "print(\"\\nTesting different inputs:\")\n",
    "for x in example_inputs:\n",
    "    print(f\"\\nInput: {x}\")\n",
    "    print(f\"Output before activation: {neuron.forward(x):.4f}\")\n",
    "    print(f\"Output after ReLU: {neuron.activate(x):.4f}\")\n",
    "\n",
    "# Visualize decision boundary for 2D inputs\n",
    "def plot_neuron_decision_boundary():\n",
    "    # Create a simplified 2D neuron\n",
    "    neuron_2d = Neuron(2)\n",
    "    \n",
    "    # Create a grid of points\n",
    "    x = np.linspace(-2, 2, 100)\n",
    "    y = np.linspace(-2, 2, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Calculate neuron output for each point\n",
    "    Z = np.zeros_like(X)\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            point = np.array([X[i,j], Y[i,j]])\n",
    "            Z[i,j] = neuron_2d.forward(point)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contour(X, Y, Z, levels=[0], colors='k')  # Decision boundary\n",
    "    plt.contourf(X, Y, Z, alpha=0.4)\n",
    "    plt.colorbar(label='Neuron Output')\n",
    "    \n",
    "    # Plot the weight vector\n",
    "    plt.quiver(0, 0, neuron_2d.weights[0], neuron_2d.weights[1], \n",
    "              angles='xy', scale_units='xy', scale=1, color='r', \n",
    "              label='Weight Vector')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Input 1')\n",
    "    plt.ylabel('Input 2')\n",
    "    plt.title('2D Neuron Decision Boundary')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_neuron_decision_boundary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cbd87f",
   "metadata": {},
   "source": [
    "# Section 5: Matrix Multiplication as Dot Products\n",
    "\n",
    "Matrix multiplication can be viewed as a series of dot products. When we multiply a matrix A by a vector x:\n",
    "- Each row of A performs a dot product with x\n",
    "- The result is a vector where each element is one of these dot products\n",
    "\n",
    "Let's visualize this connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_matrix_vector_product():\n",
    "    # Create a 2x3 matrix and a 3D vector\n",
    "    A = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "    x = np.array([0.5, 1.0, -0.5])\n",
    "    \n",
    "    # Compute the matrix-vector product\n",
    "    result = A @ x\n",
    "    \n",
    "    print(\"Matrix A:\")\n",
    "    print(A)\n",
    "    print(\"\\nVector x:\", x)\n",
    "    print(\"\\nMatrix-vector product (A @ x):\", result)\n",
    "    \n",
    "    # Show the dot product calculations\n",
    "    print(\"\\nStep-by-step dot products:\")\n",
    "    for i, row in enumerate(A):\n",
    "        print(f\"Row {i+1} · x = \", end=\"\")\n",
    "        for j, (a, b) in enumerate(zip(row, x)):\n",
    "            print(f\"{a}*{b}\", end=\"\")\n",
    "            if j < len(x) - 1:\n",
    "                print(\" + \", end=\"\")\n",
    "        print(f\" = {np.dot(row, x)}\")\n",
    "\n",
    "# Demonstrate the relationship\n",
    "visualize_matrix_vector_product()\n",
    "\n",
    "# Now let's visualize how matrix multiplication transforms space\n",
    "def plot_matrix_transformation():\n",
    "    # Create a simple 2x2 matrix\n",
    "    A = np.array([[2, 1],\n",
    "                  [1, 2]])\n",
    "    \n",
    "    # Create a grid of points\n",
    "    x = np.linspace(-2, 2, 10)\n",
    "    y = np.linspace(-2, 2, 10)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    \n",
    "    # Transform points\n",
    "    transformed = points @ A\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Original points\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(points[:, 0], points[:, 1], alpha=0.5)\n",
    "    plt.axhline(y=0, color='k', linestyle=':')\n",
    "    plt.axvline(x=0, color='k', linestyle=':')\n",
    "    plt.grid(True)\n",
    "    plt.title('Original Points')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    # Transformed points\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(transformed[:, 0], transformed[:, 1], alpha=0.5)\n",
    "    plt.axhline(y=0, color='k', linestyle=':')\n",
    "    plt.axvline(x=0, color='k', linestyle=':')\n",
    "    plt.grid(True)\n",
    "    plt.title('After Matrix Transformation')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_matrix_transformation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16283f7",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### Exercise 1: Manual Dot Product\n",
    "Given two 5D vectors, calculate their dot product by hand, then verify with NumPy:\n",
    "```python\n",
    "a = [1, 2, -1, 3, 0]\n",
    "b = [0, 1, 2, -1, 3]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define vectors\n",
    "a = np.array([1, 2, -1, 3, 0])\n",
    "b = np.array([0, 1, 2, -1, 3])\n",
    "\n",
    "# Calculate dot product using NumPy\n",
    "numpy_dot = np.dot(a, b)\n",
    "print(f\"NumPy dot product: {numpy_dot}\")\n",
    "\n",
    "# Now it's your turn to calculate by hand!\n",
    "# The result should be: (1×0) + (2×1) + (-1×2) + (3×-1) + (0×3) = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c2708",
   "metadata": {},
   "source": [
    "### Exercise 2: Cosine Similarity\n",
    "Calculate the cosine similarity between two document vectors:\n",
    "\n",
    "```python\n",
    "doc1 = [2, 1, 0, 2, 0, 1, 1]  # Frequencies of words in document 1\n",
    "doc2 = [1, 1, 1, 0, 1, 0, 1]  # Frequencies of words in document 2\n",
    "```\n",
    "\n",
    "Hint: Remember that cosine similarity is the dot product divided by the product of the magnitudes:\n",
    "cos(θ) = (a·b)/(||a||×||b||)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ea8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define document vectors\n",
    "doc1 = np.array([2, 1, 0, 2, 0, 1, 1])\n",
    "doc2 = np.array([1, 1, 1, 0, 1, 0, 1])\n",
    "\n",
    "# TODO: Calculate dot product of doc1 and doc2\n",
    "dot_product = None\n",
    "\n",
    "# TODO: Calculate magnitudes of both vectors\n",
    "magnitude_doc1 = None\n",
    "magnitude_doc2 = None\n",
    "\n",
    "# TODO: Calculate cosine similarity\n",
    "cosine_similarity = None\n",
    "\n",
    "# Verify with NumPy's built-in function\n",
    "numpy_cosine = np.dot(doc1, doc2) / (np.linalg.norm(doc1) * np.linalg.norm(doc2))\n",
    "print(f\"NumPy cosine similarity: {numpy_cosine:.4f}\")\n",
    "\n",
    "# Your result should match this value!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8443b1",
   "metadata": {},
   "source": [
    "### Exercise 3: Neural Network Weight Update\n",
    "In a simple neural network, we use dot products to compute the weighted sum of inputs. Given:\n",
    "- Input vector: x = [0.5, -0.2, 0.1]\n",
    "- Current weights: w = [0.4, 0.3, 0.6]\n",
    "- Learning rate: α = 0.1\n",
    "- Target output: y = 0.8\n",
    "- Actual output: ŷ = sigmoid(w·x)\n",
    "\n",
    "1. Calculate the actual output ŷ using the sigmoid function\n",
    "2. Calculate the error: E = (y - ŷ)²\n",
    "3. Calculate the gradient with respect to weights\n",
    "4. Update the weights using: w_new = w + α × gradient\n",
    "\n",
    "Note: The sigmoid function is provided: sigmoid(x) = 1/(1 + e^(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Given values\n",
    "x = np.array([0.5, -0.2, 0.1])\n",
    "w = np.array([0.4, 0.3, 0.6])\n",
    "learning_rate = 0.1\n",
    "target = 0.8\n",
    "\n",
    "# TODO: Calculate the weighted sum (dot product)\n",
    "weighted_sum = None\n",
    "\n",
    "# TODO: Calculate actual output using sigmoid\n",
    "output = None\n",
    "\n",
    "# TODO: Calculate error\n",
    "error = None\n",
    "\n",
    "# TODO: Calculate gradient\n",
    "# Hint: gradient = error × sigmoid_derivative(weighted_sum) × input\n",
    "gradient = None\n",
    "\n",
    "# TODO: Update weights\n",
    "new_weights = None\n",
    "\n",
    "# Print results\n",
    "print(f\"Original weights: {w}\")\n",
    "print(f\"New weights: {new_weights}\")\n",
    "\n",
    "# Verify the new output is closer to the target\n",
    "new_output = sigmoid(np.dot(new_weights, x))\n",
    "print(f\"Original output: {output:.4f}\")\n",
    "print(f\"New output: {new_output:.4f}\")\n",
    "print(f\"Target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04237ac",
   "metadata": {},
   "source": [
    "# Solutions\n",
    "\n",
    "The solutions to the exercises are provided below. Try to solve the exercises yourself before looking at the solutions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d5f4b",
   "metadata": {},
   "source": [
    "### Solution to Exercise 1\n",
    "\n",
    "The dot product calculation:\n",
    "(1 × 0) + (2 × 1) + (-1 × 2) + (3 × -1) + (0 × 3) = \n",
    "0 + 2 + (-2) + (-3) + 0 = -3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab87e0e",
   "metadata": {},
   "source": [
    "### Solution to Exercise 2\n",
    "\n",
    "Here's how to calculate the cosine similarity:\n",
    "\n",
    "1. Dot product:\n",
    "   (2×1) + (1×1) + (0×1) + (2×0) + (0×1) + (1×0) + (1×1) = 2 + 1 + 0 + 0 + 0 + 0 + 1 = 4\n",
    "\n",
    "2. Magnitudes:\n",
    "   ||doc1|| = √(2² + 1² + 0² + 2² + 0² + 1² + 1²) = √(4 + 1 + 0 + 4 + 0 + 1 + 1) = √11\n",
    "   ||doc2|| = √(1² + 1² + 1² + 0² + 1² + 0² + 1²) = √(1 + 1 + 1 + 0 + 1 + 0 + 1) = √5\n",
    "\n",
    "3. Cosine similarity:\n",
    "   cos(θ) = 4 / (√11 × √5) ≈ 0.5411"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e9cd4",
   "metadata": {},
   "source": [
    "### Solution to Exercise 3\n",
    "\n",
    "Here's the step-by-step solution:\n",
    "\n",
    "1. Calculate weighted sum (dot product):\n",
    "   w·x = (0.4 × 0.5) + (0.3 × -0.2) + (0.6 × 0.1)\n",
    "   = 0.2 - 0.06 + 0.06\n",
    "   = 0.2\n",
    "\n",
    "2. Calculate output:\n",
    "   ŷ = sigmoid(0.2) = 1/(1 + e⁻⁰·²) ≈ 0.5498\n",
    "\n",
    "3. Calculate error:\n",
    "   E = (y - ŷ)² = (0.8 - 0.5498)² ≈ 0.0625\n",
    "\n",
    "4. Calculate gradient:\n",
    "   gradient = error × sigmoid_derivative(weighted_sum) × input\n",
    "   = (0.8 - 0.5498) × (0.5498 × (1 - 0.5498)) × [0.5, -0.2, 0.1]\n",
    "   ≈ 0.2502 × 0.2475 × [0.5, -0.2, 0.1]\n",
    "\n",
    "5. Update weights:\n",
    "   w_new = w + α × gradient\n",
    "\n",
    "This will move the output closer to the target value of 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b884dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Exercise 1 Solution:\")\n",
    "a = np.array([1, 2, -1, 3, 0])\n",
    "b = np.array([0, 1, 2, -1, 3])\n",
    "dot_product = np.dot(a, b)\n",
    "print(f\"Dot product: {dot_product}\")\n",
    "print()\n",
    "\n",
    "print(\"Exercise 2 Solution:\")\n",
    "doc1 = np.array([2, 1, 0, 2, 0, 1, 1])\n",
    "doc2 = np.array([1, 1, 1, 0, 1, 0, 1])\n",
    "\n",
    "# Calculate dot product\n",
    "dot_product = np.dot(doc1, doc2)\n",
    "\n",
    "# Calculate magnitudes\n",
    "magnitude_doc1 = np.sqrt(np.sum(doc1**2))\n",
    "magnitude_doc2 = np.sqrt(np.sum(doc2**2))\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = dot_product / (magnitude_doc1 * magnitude_doc2)\n",
    "\n",
    "print(f\"Dot product: {dot_product}\")\n",
    "print(f\"Magnitude of doc1: {magnitude_doc1:.4f}\")\n",
    "print(f\"Magnitude of doc2: {magnitude_doc2:.4f}\")\n",
    "print(f\"Cosine similarity: {cosine_similarity:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Exercise 3 Solution:\")\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Given values\n",
    "x = np.array([0.5, -0.2, 0.1])\n",
    "w = np.array([0.4, 0.3, 0.6])\n",
    "learning_rate = 0.1\n",
    "target = 0.8\n",
    "\n",
    "# Calculate weighted sum\n",
    "weighted_sum = np.dot(w, x)\n",
    "\n",
    "# Calculate output\n",
    "output = sigmoid(weighted_sum)\n",
    "\n",
    "# Calculate error\n",
    "error = target - output\n",
    "\n",
    "# Calculate gradient\n",
    "gradient = error * sigmoid_derivative(weighted_sum) * x\n",
    "\n",
    "# Update weights\n",
    "new_weights = w + learning_rate * gradient\n",
    "\n",
    "print(f\"Original weights: {w}\")\n",
    "print(f\"Gradient: {gradient}\")\n",
    "print(f\"New weights: {new_weights}\")\n",
    "print(f\"Original output: {output:.4f}\")\n",
    "print(f\"New output: {sigmoid(np.dot(new_weights, x)):.4f}\")\n",
    "print(f\"Target: {target}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
