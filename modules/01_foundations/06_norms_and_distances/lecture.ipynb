{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ebe72a",
   "metadata": {},
   "source": [
    "# Lecture 6: Norms and Distances in Machine Learning\n",
    "\n",
    "[![Watch the Video](https://img.shields.io/badge/Watch%20on%20YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtube.com/your-channel)\n",
    "\n",
    "In this lecture, we'll explore how to measure vectors and the distances between them, concepts fundamental to many machine learning algorithms.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand different types of norms and their properties\n",
    "- Learn when to use different distance metrics\n",
    "- Apply distance metrics in machine learning contexts\n",
    "- Implement custom metrics for specific problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_norm_circle(p, points=1000):\n",
    "    \"\"\"Plot the unit circle for different p-norms\"\"\"\n",
    "    theta = np.linspace(0, 2*np.pi, points)\n",
    "    x = np.cos(theta)\n",
    "    y = np.sin(theta)\n",
    "    \n",
    "    # Convert to p-norm unit circle\n",
    "    r = (np.abs(x)**p + np.abs(y)**p)**(1/p)\n",
    "    x = x/r\n",
    "    y = y/r\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a992fd5",
   "metadata": {},
   "source": [
    "## 1. Understanding Norms\n",
    "\n",
    "A norm is a function that assigns a length or size to vectors. Properties of norms:\n",
    "1. Non-negativity: $\\|\\mathbf{x}\\| \\geq 0$\n",
    "2. Definiteness: $\\|\\mathbf{x}\\| = 0$ if and only if $\\mathbf{x} = 0$\n",
    "3. Homogeneity: $\\|\\alpha\\mathbf{x}\\| = |\\alpha|\\|\\mathbf{x}\\|$\n",
    "4. Triangle Inequality: $\\|\\mathbf{x} + \\mathbf{y}\\| \\leq \\|\\mathbf{x}\\| + \\|\\mathbf{y}\\|$\n",
    "\n",
    "Common norms:\n",
    "- L1 (Manhattan): $\\|\\mathbf{x}\\|_1 = \\sum_i |x_i|$\n",
    "- L2 (Euclidean): $\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_i x_i^2}$\n",
    "- L∞ (Maximum): $\\|\\mathbf{x}\\|_\\infty = \\max_i |x_i|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize different p-norm unit circles\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# L1 norm\n",
    "plt.subplot(131)\n",
    "x1, y1 = plot_norm_circle(1)\n",
    "plt.plot(x1, y1, 'b-', label='L1 norm')\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.title('L1 (Manhattan) Norm\\nUnit Circle')\n",
    "plt.legend()\n",
    "\n",
    "# L2 norm\n",
    "plt.subplot(132)\n",
    "x2, y2 = plot_norm_circle(2)\n",
    "plt.plot(x2, y2, 'r-', label='L2 norm')\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.title('L2 (Euclidean) Norm\\nUnit Circle')\n",
    "plt.legend()\n",
    "\n",
    "# L∞ norm\n",
    "plt.subplot(133)\n",
    "x_inf, y_inf = plot_norm_circle(float('inf'))\n",
    "plt.plot(x_inf, y_inf, 'g-', label='L∞ norm')\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.title('L∞ (Maximum) Norm\\nUnit Circle')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534c617",
   "metadata": {},
   "source": [
    "## 2. Distance Metrics\n",
    "\n",
    "Distance metrics are derived from norms and measure the separation between vectors. Common distance metrics include:\n",
    "\n",
    "1. Euclidean Distance: $d(\\mathbf{x}, \\mathbf{y}) = \\|\\mathbf{x} - \\mathbf{y}\\|_2$\n",
    "2. Manhattan Distance: $d(\\mathbf{x}, \\mathbf{y}) = \\|\\mathbf{x} - \\mathbf{y}\\|_1$\n",
    "3. Cosine Distance: $d(\\mathbf{x}, \\mathbf{y}) = 1 - \\frac{\\mathbf{x} \\cdot \\mathbf{y}}{\\|\\mathbf{x}\\|_2\\|\\mathbf{y}\\|_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random 2D points\n",
    "np.random.seed(42)\n",
    "points = np.random.randn(5, 2)\n",
    "reference_point = np.array([0, 0])\n",
    "\n",
    "# Calculate distances using different metrics\n",
    "euclidean_dist = euclidean_distances([reference_point], points)[0]\n",
    "manhattan_dist = manhattan_distances([reference_point], points)[0]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot points and distances\n",
    "plt.subplot(121)\n",
    "plt.scatter(points[:, 0], points[:, 1], c='blue', label='Points')\n",
    "plt.scatter([0], [0], c='red', label='Reference')\n",
    "\n",
    "# Draw lines for both metrics\n",
    "for i, point in enumerate(points):\n",
    "    plt.plot([0, point[0]], [0, point[1]], 'g--', alpha=0.3)\n",
    "    \n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.title('Points and Their Distances')\n",
    "plt.legend()\n",
    "\n",
    "# Bar plot comparing distances\n",
    "plt.subplot(122)\n",
    "x = np.arange(len(points))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, euclidean_dist, width, label='Euclidean')\n",
    "plt.bar(x + width/2, manhattan_dist, width, label='Manhattan')\n",
    "plt.xlabel('Point Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Distance Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the distances\n",
    "print(\"Distances from origin:\")\n",
    "for i in range(len(points)):\n",
    "    print(f\"\\nPoint {i+1} at {points[i]}:\")\n",
    "    print(f\"Euclidean distance: {euclidean_dist[i]:.2f}\")\n",
    "    print(f\"Manhattan distance: {manhattan_dist[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a46966",
   "metadata": {},
   "source": [
    "## 3. Applications in Machine Learning\n",
    "\n",
    "Different norms and distances are used in various ML contexts:\n",
    "\n",
    "1. **L1 Regularization (Lasso)**\n",
    "   - Promotes sparsity\n",
    "   - Feature selection\n",
    "\n",
    "2. **L2 Regularization (Ridge)**\n",
    "   - Prevents overfitting\n",
    "   - Stabilizes solutions\n",
    "\n",
    "3. **Distance-based Algorithms**\n",
    "   - k-Nearest Neighbors\n",
    "   - k-Means Clustering\n",
    "   - DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8dc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Effect of different norms in regularization\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 2)\n",
    "y = 3*X[:, 0] + 0.5*X[:, 1] + np.random.randn(100) * 0.1\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit models with different regularization\n",
    "alphas = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "lasso_coefs = []\n",
    "ridge_coefs = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Lasso (L1)\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_scaled, y)\n",
    "    lasso_coefs.append(lasso.coef_)\n",
    "    \n",
    "    # Ridge (L2)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_scaled, y)\n",
    "    ridge_coefs.append(ridge.coef_)\n",
    "\n",
    "# Plot coefficients vs regularization strength\n",
    "lasso_coefs = np.array(lasso_coefs)\n",
    "ridge_coefs = np.array(ridge_coefs)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(alphas, lasso_coefs[:, 0], 'b-', label='Feature 1')\n",
    "plt.plot(alphas, lasso_coefs[:, 1], 'r-', label='Feature 2')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (regularization strength)')\n",
    "plt.ylabel('Coefficient value')\n",
    "plt.title('Lasso (L1) Regularization')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(alphas, ridge_coefs[:, 0], 'b-', label='Feature 1')\n",
    "plt.plot(alphas, ridge_coefs[:, 1], 'r-', label='Feature 2')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (regularization strength)')\n",
    "plt.ylabel('Coefficient value')\n",
    "plt.title('Ridge (L2) Regularization')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f540758c",
   "metadata": {},
   "source": [
    "## 4. Custom Distance Metrics\n",
    "\n",
    "Sometimes we need to define custom distance metrics for specific problems:\n",
    "\n",
    "1. Time series data: Dynamic Time Warping\n",
    "2. Text data: Edit Distance\n",
    "3. Structured data: Domain-specific metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776fac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_distance(x, y, weights=None):\n",
    "    \"\"\"\n",
    "    Custom weighted Euclidean distance\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x, y: array-like\n",
    "        Vectors to compute distance between\n",
    "    weights: array-like, optional\n",
    "        Importance weights for each dimension\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(x)\n",
    "    return np.sqrt(np.sum(weights * (x - y)**2))\n",
    "\n",
    "# Example usage with feature importance weights\n",
    "point1 = np.array([1, 2])\n",
    "point2 = np.array([4, 6])\n",
    "weights = np.array([2, 1])  # First feature twice as important\n",
    "\n",
    "standard_dist = np.linalg.norm(point1 - point2)\n",
    "weighted_dist = custom_distance(point1, point2, weights)\n",
    "\n",
    "print(f\"Standard Euclidean distance: {standard_dist:.2f}\")\n",
    "print(f\"Weighted distance: {weighted_dist:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbdabcf",
   "metadata": {},
   "source": [
    "## 5. Practice Exercises\n",
    "\n",
    "1. Implement different p-norms from scratch\n",
    "2. Compare clustering results using different distance metrics\n",
    "3. Create a custom distance metric for a specific problem\n",
    "4. Explore the effect of different norms in regularization\n",
    "\n",
    "Write your solutions in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccde611",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next lecture, we'll introduce matrices and explore how they can represent linear transformations.\n",
    "\n",
    "### Preparation for Next Lecture\n",
    "1. Review vector operations and norms\n",
    "2. Think about how we might represent transformations of vectors\n",
    "3. Consider why matrices are useful in machine learning\n",
    "\n",
    "### Additional Resources\n",
    "- [Interactive Norm Visualization](../../resources/visualizations/norms.html)\n",
    "- [Distance Metrics Cheat Sheet](../../resources/cheat_sheets/distances.pdf)\n",
    "- [Regularization in Machine Learning](../../resources/articles/regularization.md)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
