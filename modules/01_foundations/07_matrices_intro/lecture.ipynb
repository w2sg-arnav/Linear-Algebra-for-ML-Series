{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29fc7de",
   "metadata": {},
   "source": [
    "# Lecture 7: Introduction to Matrices\n",
    "\n",
    "[![Watch the Video](https://img.shields.io/badge/Watch%20on%20YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtube.com/your-channel)\n",
    "\n",
    "This lecture introduces matrices as fundamental tools in linear algebra and machine learning. We'll explore how matrices represent data, transformations, and relationships.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand matrix notation and operations\n",
    "- Learn about special types of matrices\n",
    "- Apply matrix operations to data manipulation\n",
    "- Visualize matrix transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_transformation(matrix, points=None, title=\"Matrix Transformation\"):\n",
    "    \"\"\"\n",
    "    Plot the effect of a 2x2 matrix transformation on a grid of points\n",
    "    or specific points if provided\n",
    "    \"\"\"\n",
    "    if points is None:\n",
    "        # Create a grid of points\n",
    "        x = np.linspace(-2, 2, 10)\n",
    "        y = np.linspace(-2, 2, 10)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed_points = points @ matrix.T\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Original points\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(points[:, 0], points[:, 1], c='blue', alpha=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.title('Original Points')\n",
    "    \n",
    "    # Transformed points\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(transformed_points[:, 0], transformed_points[:, 1], \n",
    "                c='red', alpha=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.title(f'After {title}')\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf15b2f8",
   "metadata": {},
   "source": [
    "## 1. Matrix Basics\n",
    "\n",
    "A matrix is a rectangular array of numbers arranged in rows and columns. In machine learning:\n",
    "- Data matrices: each row is a sample, each column a feature\n",
    "- Weight matrices: parameters in neural networks\n",
    "- Transformation matrices: linear operations on vectors\n",
    "\n",
    "Example of a 2×3 matrix:\n",
    "$A = \\begin{bmatrix} \n",
    "a_{11} & a_{12} & a_{13} \\\\\n",
    "a_{21} & a_{22} & a_{23}\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display different types of matrices\n",
    "# 1. Data matrix\n",
    "data_matrix = np.random.randn(5, 3)  # 5 samples, 3 features\n",
    "\n",
    "# 2. Identity matrix\n",
    "identity = np.eye(3)\n",
    "\n",
    "# 3. Zero matrix\n",
    "zeros = np.zeros((2, 4))\n",
    "\n",
    "# 4. Ones matrix\n",
    "ones = np.ones((3, 2))\n",
    "\n",
    "# Display matrices\n",
    "print(\"Data Matrix (5x3):\")\n",
    "print(data_matrix)\n",
    "print(\"\\nIdentity Matrix (3x3):\")\n",
    "print(identity)\n",
    "print(\"\\nZero Matrix (2x4):\")\n",
    "print(zeros)\n",
    "print(\"\\nOnes Matrix (3x2):\")\n",
    "print(ones)\n",
    "\n",
    "# Visualize data matrix\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(data_matrix, annot=True, cmap='coolwarm', \n",
    "            xticklabels=['Feature 1', 'Feature 2', 'Feature 3'],\n",
    "            yticklabels=[f'Sample {i+1}' for i in range(5)])\n",
    "plt.title('Data Matrix Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907d019",
   "metadata": {},
   "source": [
    "## 2. Matrix Operations\n",
    "\n",
    "Basic matrix operations include:\n",
    "1. Addition and Subtraction\n",
    "2. Scalar Multiplication\n",
    "3. Matrix Multiplication\n",
    "4. Transpose\n",
    "5. Trace\n",
    "6. Determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb4435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two matrices\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "B = np.array([[5, 6],\n",
    "              [7, 8]])\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nMatrix B:\")\n",
    "print(B)\n",
    "\n",
    "# 1. Addition\n",
    "print(\"\\nA + B:\")\n",
    "print(A + B)\n",
    "\n",
    "# 2. Scalar multiplication\n",
    "scalar = 2\n",
    "print(f\"\\n{scalar} × A:\")\n",
    "print(scalar * A)\n",
    "\n",
    "# 3. Matrix multiplication\n",
    "print(\"\\nA × B:\")\n",
    "print(A @ B)\n",
    "\n",
    "# 4. Transpose\n",
    "print(\"\\nA transpose:\")\n",
    "print(A.T)\n",
    "\n",
    "# 5. Trace\n",
    "print(f\"\\nTrace of A: {np.trace(A)}\")\n",
    "\n",
    "# 6. Determinant\n",
    "print(f\"\\nDeterminant of A: {np.linalg.det(A)}\")\n",
    "\n",
    "# Visualize matrix multiplication\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(131)\n",
    "sns.heatmap(A, annot=True, cmap='viridis')\n",
    "plt.title('Matrix A')\n",
    "\n",
    "plt.subplot(132)\n",
    "sns.heatmap(B, annot=True, cmap='viridis')\n",
    "plt.title('Matrix B')\n",
    "\n",
    "plt.subplot(133)\n",
    "sns.heatmap(A @ B, annot=True, cmap='viridis')\n",
    "plt.title('A × B')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc58ca5",
   "metadata": {},
   "source": [
    "## 3. Special Matrices\n",
    "\n",
    "Several special types of matrices are important in machine learning:\n",
    "\n",
    "1. Identity Matrix: Diagonal of ones, zeros elsewhere\n",
    "2. Diagonal Matrix: Non-zero elements only on diagonal\n",
    "3. Symmetric Matrix: Equal to its transpose\n",
    "4. Orthogonal Matrix: Its transpose is its inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b114a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and visualize special matrices\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# 1. Identity matrix\n",
    "I = np.eye(4)\n",
    "plt.subplot(141)\n",
    "sns.heatmap(I, annot=True, cmap='viridis')\n",
    "plt.title('Identity Matrix')\n",
    "\n",
    "# 2. Diagonal matrix\n",
    "D = np.diag([1, 2, 3, 4])\n",
    "plt.subplot(142)\n",
    "sns.heatmap(D, annot=True, cmap='viridis')\n",
    "plt.title('Diagonal Matrix')\n",
    "\n",
    "# 3. Symmetric matrix\n",
    "S = np.array([[1, 2, 3],\n",
    "              [2, 4, 5],\n",
    "              [3, 5, 6]])\n",
    "plt.subplot(143)\n",
    "sns.heatmap(S, annot=True, cmap='viridis')\n",
    "plt.title('Symmetric Matrix')\n",
    "\n",
    "# 4. Orthogonal matrix (rotation matrix)\n",
    "theta = np.pi/4  # 45 degrees\n",
    "O = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "              [np.sin(theta), np.cos(theta)]])\n",
    "plt.subplot(144)\n",
    "sns.heatmap(O, annot=True, cmap='viridis')\n",
    "plt.title('Orthogonal Matrix\\n(Rotation)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Verify properties\n",
    "print(\"Properties of special matrices:\")\n",
    "print(\"\\nSymmetric matrix equals its transpose:\")\n",
    "print(np.allclose(S, S.T))\n",
    "\n",
    "print(\"\\nOrthogonal matrix × its transpose ≈ Identity:\")\n",
    "print(np.allclose(O @ O.T, np.eye(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9236760",
   "metadata": {},
   "source": [
    "## 4. Matrices as Transformations\n",
    "\n",
    "Matrices can represent various linear transformations:\n",
    "1. Scaling\n",
    "2. Rotation\n",
    "3. Reflection\n",
    "4. Shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9646a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different transformation matrices\n",
    "# 1. Scaling\n",
    "scale_matrix = np.array([[2, 0],\n",
    "                        [0, 0.5]])  # Scale x by 2, y by 0.5\n",
    "\n",
    "# 2. Rotation (45 degrees)\n",
    "theta = np.pi/4\n",
    "rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                           [np.sin(theta), np.cos(theta)]])\n",
    "\n",
    "# 3. Reflection (about y-axis)\n",
    "reflection_matrix = np.array([[-1, 0],\n",
    "                            [0, 1]])\n",
    "\n",
    "# 4. Shear\n",
    "shear_matrix = np.array([[1, 0.5],\n",
    "                        [0, 1]])\n",
    "\n",
    "# Visualize all transformations\n",
    "transformations = {\n",
    "    'Scaling': scale_matrix,\n",
    "    'Rotation': rotation_matrix,\n",
    "    'Reflection': reflection_matrix,\n",
    "    'Shear': shear_matrix\n",
    "}\n",
    "\n",
    "# Create a grid of points for visualization\n",
    "x = np.linspace(-2, 2, 5)\n",
    "y = np.linspace(-2, 2, 5)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "\n",
    "# Plot each transformation\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "for i, (name, matrix) in enumerate(transformations.items(), 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    transformed_points = points @ matrix.T\n",
    "    \n",
    "    # Plot original points\n",
    "    plt.scatter(points[:, 0], points[:, 1], c='blue', alpha=0.5, label='Original')\n",
    "    # Plot transformed points\n",
    "    plt.scatter(transformed_points[:, 0], transformed_points[:, 1], \n",
    "                c='red', alpha=0.5, label='Transformed')\n",
    "    \n",
    "    # Add grid lines to show the transformation of the coordinate system\n",
    "    for x_coord in x:\n",
    "        plt.axvline(x=x_coord, color='gray', alpha=0.2)\n",
    "    for y_coord in y:\n",
    "        plt.axhline(y=y_coord, color='gray', alpha=0.2)\n",
    "        \n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.title(f'{name} Transformation')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6696238a",
   "metadata": {},
   "source": [
    "## 5. Applications in Machine Learning\n",
    "\n",
    "Matrices are fundamental in many ML algorithms:\n",
    "\n",
    "1. **Data Representation**\n",
    "   - Feature matrices\n",
    "   - One-hot encoding\n",
    "\n",
    "2. **Linear Regression**\n",
    "   - Weight matrices\n",
    "   - Normal equations\n",
    "\n",
    "3. **Neural Networks**\n",
    "   - Weight matrices\n",
    "   - Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ddc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Linear Regression using matrices\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "X = np.random.randn(100, 2)  # 100 samples, 2 features\n",
    "true_weights = np.array([2, -1])\n",
    "y = X @ true_weights + np.random.randn(100) * 0.1\n",
    "\n",
    "# Add bias term\n",
    "X_b = np.column_stack([np.ones(len(X)), X])\n",
    "\n",
    "# Solve using normal equation: w = (X^T X)^(-1) X^T y\n",
    "weights = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
    "\n",
    "print(\"True weights:\", true_weights)\n",
    "print(\"Estimated weights:\", weights[1:])\n",
    "print(\"Bias term:\", weights[0])\n",
    "\n",
    "# Visualize predictions\n",
    "y_pred = X_b @ weights\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(range(len(y)), y, alpha=0.5, label='True')\n",
    "plt.scatter(range(len(y)), y_pred, alpha=0.5, label='Predicted')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Value')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.legend()\n",
    "\n",
    "# Plot residuals\n",
    "plt.subplot(122)\n",
    "residuals = y - y_pred\n",
    "plt.hist(residuals, bins=20)\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Residual Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a08a12",
   "metadata": {},
   "source": [
    "## 6. Practice Exercises\n",
    "\n",
    "1. Implement matrix multiplication from scratch\n",
    "2. Create and apply different transformation matrices\n",
    "3. Solve a system of linear equations using matrices\n",
    "4. Implement a simple neural network layer using matrix operations\n",
    "\n",
    "Write your solutions in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2eb725",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next lecture, we'll preview vector calculus concepts that will be essential for understanding optimization in machine learning.\n",
    "\n",
    "### Preparation for Next Lecture\n",
    "1. Review matrix operations\n",
    "2. Think about how we might use matrices to represent changes\n",
    "3. Consider why calculus is important in machine learning\n",
    "\n",
    "### Additional Resources\n",
    "- [Interactive Matrix Operations](../../resources/visualizations/matrix_ops.html)\n",
    "- [Matrix Operations Cheat Sheet](../../resources/cheat_sheets/matrices.pdf)\n",
    "- [3Blue1Brown: Linear transformations](https://www.3blue1brown.com/lessons/linear-transformations)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
