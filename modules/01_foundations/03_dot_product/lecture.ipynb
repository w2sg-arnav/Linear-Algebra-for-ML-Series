{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ed2c03",
   "metadata": {},
   "source": [
    "# Lecture 3: The Dot Product - Measuring Similarity and Projection\n",
    "\n",
    "[![Watch the Video](https://img.shields.io/badge/Watch%20on%20YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://youtube.com/your-channel)\n",
    "\n",
    "Welcome to our third lecture! Today, we'll explore one of the most fundamental operations in linear algebra and machine learning: the dot product. This operation is crucial for understanding similarity measures, neural networks, and many other ML concepts.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the dot product both algebraically and geometrically\n",
    "- Master the connection between dot products and vector similarity\n",
    "- Learn how dot products are used in machine learning\n",
    "- Implement dot product operations efficiently in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function for vector visualization\n",
    "def plot_vector_and_projection(v1, v2, show_projection=True):\n",
    "    \"\"\"Plot two vectors and optionally show the projection of v1 onto v2\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot original vectors\n",
    "    plt.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1, \n",
    "              color='blue', label='v1')\n",
    "    plt.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1, \n",
    "              color='red', label='v2')\n",
    "    \n",
    "    if show_projection:\n",
    "        # Calculate projection\n",
    "        v2_unit = v2 / np.linalg.norm(v2)\n",
    "        proj_length = np.dot(v1, v2_unit)\n",
    "        proj_vector = proj_length * v2_unit\n",
    "        \n",
    "        # Plot projection\n",
    "        plt.quiver(0, 0, proj_vector[0], proj_vector[1], angles='xy', \n",
    "                  scale_units='xy', scale=1, color='green', \n",
    "                  label='projection of v1 onto v2')\n",
    "        \n",
    "        # Plot dashed line for projection visualization\n",
    "        plt.plot([v1[0], proj_vector[0]], [v1[1], proj_vector[1]], \n",
    "                'k--', alpha=0.3)\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    plt.title('Vector Projection Visualization')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76b67a",
   "metadata": {},
   "source": [
    "## 1. Understanding the Dot Product\n",
    "\n",
    "The dot product (also called scalar product) between two vectors is defined as:\n",
    "\n",
    "$\\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^n a_i b_i = a_1b_1 + a_2b_2 + ... + a_nb_n$\n",
    "\n",
    "Geometrically, it can also be expressed as:\n",
    "\n",
    "$\\mathbf{a} \\cdot \\mathbf{b} = \\|\\mathbf{a}\\| \\|\\mathbf{b}\\| \\cos(\\theta)$\n",
    "\n",
    "where $\\theta$ is the angle between the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61c5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Computing dot product algebraically\n",
    "v1 = np.array([3, 4])\n",
    "v2 = np.array([1, 2])\n",
    "\n",
    "# Method 1: Element-wise multiplication and sum\n",
    "dot_product1 = np.sum(v1 * v2)\n",
    "\n",
    "# Method 2: Using np.dot\n",
    "dot_product2 = np.dot(v1, v2)\n",
    "\n",
    "# Method 3: Using @ operator\n",
    "dot_product3 = v1 @ v2\n",
    "\n",
    "print(f\"Dot product using sum of products: {dot_product1}\")\n",
    "print(f\"Dot product using np.dot(): {dot_product2}\")\n",
    "print(f\"Dot product using @ operator: {dot_product3}\")\n",
    "\n",
    "# Visualize the vectors\n",
    "plot_vector_and_projection(v1, v2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629bb00",
   "metadata": {},
   "source": [
    "## 2. Geometric Interpretation\n",
    "\n",
    "The dot product has several important geometric interpretations:\n",
    "\n",
    "1. **Projection**: $\\|\\text{proj}_{\\mathbf{b}}\\mathbf{a}\\| = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{b}\\|}$\n",
    "2. **Angle between vectors**: $\\cos(\\theta) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\| \\|\\mathbf{b}\\|}$\n",
    "3. **Orthogonality**: If $\\mathbf{a} \\cdot \\mathbf{b} = 0$, the vectors are perpendicular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a589333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the angle between two vectors\n",
    "def angle_between_vectors(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norms = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    cos_angle = dot_product / norms\n",
    "    return np.arccos(np.clip(cos_angle, -1.0, 1.0))  # clip to handle numerical errors\n",
    "\n",
    "# Example vectors\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([1, 1])\n",
    "\n",
    "angle = angle_between_vectors(v1, v2)\n",
    "print(f\"Angle between vectors: {np.degrees(angle):.2f} degrees\")\n",
    "\n",
    "# Visualize\n",
    "plot_vector_and_projection(v1, v2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa20cb",
   "metadata": {},
   "source": [
    "## 3. Applications in Machine Learning\n",
    "\n",
    "The dot product is fundamental in many ML applications:\n",
    "\n",
    "1. **Similarity Measures**\n",
    "   - Cosine similarity in document analysis\n",
    "   - Feature similarity in recommendation systems\n",
    "\n",
    "2. **Neural Networks**\n",
    "   - Computing weighted sums in neurons\n",
    "   - Forward propagation operations\n",
    "\n",
    "3. **Linear Regression**\n",
    "   - Computing predictions (weights Â· features)\n",
    "   - Normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Document Similarity using Cosine Similarity\n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# Example documents represented as word count vectors\n",
    "# Vector dimensions: [cat, dog, pet, fish, bird]\n",
    "doc1 = np.array([2, 1, 2, 0, 0])  # \"cat cat pet dog pet\"\n",
    "doc2 = np.array([1, 2, 1, 0, 0])  # \"cat dog dog pet\"\n",
    "doc3 = np.array([0, 0, 1, 2, 1])  # \"pet fish fish bird\"\n",
    "\n",
    "print(\"Similarity between doc1 and doc2:\", cosine_similarity(doc1, doc2))\n",
    "print(\"Similarity between doc1 and doc3:\", cosine_similarity(doc1, doc3))\n",
    "print(\"Similarity between doc2 and doc3:\", cosine_similarity(doc2, doc3))\n",
    "\n",
    "# Visualize similarities as a heatmap\n",
    "similarities = np.array([\n",
    "    [cosine_similarity(doc1, doc1), cosine_similarity(doc1, doc2), cosine_similarity(doc1, doc3)],\n",
    "    [cosine_similarity(doc2, doc1), cosine_similarity(doc2, doc2), cosine_similarity(doc2, doc3)],\n",
    "    [cosine_similarity(doc3, doc1), cosine_similarity(doc3, doc2), cosine_similarity(doc3, doc3)]\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(similarities, annot=True, cmap='YlOrRd', \n",
    "            xticklabels=['Doc 1', 'Doc 2', 'Doc 3'],\n",
    "            yticklabels=['Doc 1', 'Doc 2', 'Doc 3'])\n",
    "plt.title('Document Similarity Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f39f80",
   "metadata": {},
   "source": [
    "## 4. Neural Network Example\n",
    "\n",
    "Let's see how dot products are used in a simple neural network computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77fc79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple neuron computation\n",
    "def neuron(input_vector, weights, bias):\n",
    "    \"\"\"Compute neuron output using dot product\"\"\"\n",
    "    activation = np.dot(input_vector, weights) + bias\n",
    "    # ReLU activation function\n",
    "    return max(0, activation)\n",
    "\n",
    "# Example\n",
    "input_vector = np.array([2, 3])  # Input features\n",
    "weights = np.array([0.5, -0.1])  # Neuron weights\n",
    "bias = 0.2  # Neuron bias\n",
    "\n",
    "output = neuron(input_vector, weights, bias)\n",
    "print(f\"Neuron output: {output}\")\n",
    "\n",
    "# Visualize the computation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(121)\n",
    "plt.quiver(0, 0, input_vector[0], input_vector[1], angles='xy', \n",
    "           scale_units='xy', scale=1, color='blue', label='input')\n",
    "plt.quiver(0, 0, weights[0], weights[1], angles='xy', \n",
    "           scale_units='xy', scale=1, color='red', label='weights')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Input and Weight Vectors')\n",
    "\n",
    "# Show computation steps\n",
    "plt.subplot(122)\n",
    "x = np.linspace(-2, 2, 100)\n",
    "relu = np.maximum(0, x)\n",
    "plt.plot(x, relu, label='ReLU activation')\n",
    "plt.axvline(x=np.dot(input_vector, weights) + bias, \n",
    "            color='r', linestyle='--', label='dot product + bias')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Activation Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c00fa",
   "metadata": {},
   "source": [
    "## 5. Practice Exercises\n",
    "\n",
    "1. Implement the dot product from scratch (without using NumPy)\n",
    "2. Create a function that finds the angle between any two vectors\n",
    "3. Implement a simple document search using cosine similarity\n",
    "4. Create a function that computes the projection of one vector onto another\n",
    "\n",
    "Write your solutions in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b52f2",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next lecture, we'll explore spans, linear combinations, and linear independence. These concepts are crucial for understanding how vectors can work together to create spaces and how we can represent data efficiently.\n",
    "\n",
    "### Preparation for Next Lecture\n",
    "1. Review the dot product concepts covered today\n",
    "2. Think about how vectors can be combined to create new vectors\n",
    "3. Practice visualizing vector operations in 2D and 3D\n",
    "\n",
    "### Additional Resources\n",
    "- [Interactive Dot Product Visualization](../../resources/visualizations/dot_product.html)\n",
    "- [Dot Product Cheat Sheet](../../resources/cheat_sheets/dot_product.pdf)\n",
    "- [3Blue1Brown: Dot Products](https://www.3blue1brown.com/lessons/dot-products)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
